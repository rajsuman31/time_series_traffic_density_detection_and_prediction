{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d585eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file is  video10.mp4\n",
      "oString is  video10/out\n",
      "['ffmpeg', '-i', 'video10.mp4', '-f', 'image2', '-vf', \"select='eq(pict_type,PICT_TYPE_I)'\", '-vsync', 'vfr', 'video10/out%05d.png']\n"
     ]
    }
   ],
   "source": [
    "import sys, getopt, os\n",
    "import subprocess\n",
    "\n",
    "def extract_keyframes():\n",
    "    \n",
    "    inFile = 'video10.mp4'\n",
    "    oString = 'video10/out'\n",
    "    print('Input file is ',inFile)\n",
    "    print('oString is ',oString)\n",
    "\n",
    "    outFile = oString + '%05d.png'\n",
    "\n",
    "    cmd = ['ffmpeg','-i', inFile,'-f', 'image2','-vf', \n",
    "               \"select='eq(pict_type,PICT_TYPE_I)'\",'-vsync','vfr',outFile]\n",
    "    print(cmd)\n",
    "    subprocess.call(cmd)\n",
    "extract_keyframes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "534887f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "code adopted from https://towardsdatascience.com/implementing-real-time-object-detection-system-using-pytorch-and-opencv-70bac41148f7\n",
    "\"\"\"\n",
    "\n",
    "# import required libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import csv\n",
    "import sys\n",
    "from time import time\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "class ObjectDetection:\n",
    "    \"\"\"\n",
    "    Class implements Yolo5 model to make inferences on a streaming video using Opencv2.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self, out_file, width, height, logging_interval):\n",
    "        \"\"\"\n",
    "        Initializes the class with the streaming video input device and output file.\n",
    "        :param video_device: Has to be the input device identifier,on which prediction is made.\n",
    "        :param out_file: A valid output file name.\n",
    "        \"\"\"\n",
    "        self.model = self.load_model()\n",
    "        self.classes = self.model.names\n",
    "        self.out_file = out_file\n",
    "        self.device = 'cpu'\n",
    "        self.width = int(width)\n",
    "        self.height = int(height)\n",
    "        self.logging_interval = int(logging_interval)\n",
    "\n",
    "    def get_video_from_device(self):\n",
    "        \"\"\"\n",
    "        Creates a new video streaming object to extract video frame by frame to make prediction on.\n",
    "        :return: opencv2 video capture object.\n",
    "        \"\"\"\n",
    "#         return cv2.VideoCapture(self._video_device)\n",
    "        return cv2.VideoCapture(\"test.mp4\")\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"\n",
    "        Loads Yolo5 model from pytorch hub.\n",
    "        :return: Trained Pytorch model.\n",
    "        \"\"\"\n",
    "        model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "        return model\n",
    "\n",
    "    def score_frame(self, frame, i):\n",
    "        \"\"\"\n",
    "        Takes a single frame as input, and scores the frame using yolo5 model.\n",
    "        :param frame: input frame in numpy/list/tuple format.\n",
    "        :return: Labels and Coordinates of objects detected by model in the frame.\n",
    "        \"\"\"\n",
    "        self.model.to(self.device)\n",
    "        frame = [frame]\n",
    "        results = self.model(frame)    \n",
    "        outString = 'video4' + str(i) + '.xlsx'\n",
    "        df = results.pandas().xyxy[0]\n",
    "        df.to_excel(outString)\n",
    "\n",
    "        labels, cord = results.xyxyn[0][:, -1].numpy(), results.xyxyn[0][:, :-1].numpy()\n",
    "        return labels, cord\n",
    "\n",
    "    def class_to_label(self, x):\n",
    "        \"\"\"\n",
    "        For a given label value, return corresponding string label.\n",
    "        :param x: numeric label\n",
    "        :return: corresponding string label\n",
    "        \"\"\"\n",
    "        return self.classes[int(x)]\n",
    "\n",
    "    def plot_boxes(self, results, frame):\n",
    "        \"\"\"\n",
    "        Takes a frame and its results as input, and plots the bounding boxes and label on to the frame.\n",
    "        :param results: contains labels and coordinates predicted by model on the given frame.\n",
    "        :param frame: Frame which has been scored.\n",
    "        :return: Frame with bounding boxes and labels ploted on it.\n",
    "        \"\"\"\n",
    "        labels, cord = results\n",
    "        n = len(labels)\n",
    "        x_shape, y_shape = frame.shape[1], frame.shape[0]\n",
    "        for i in range(n):\n",
    "            row = cord[i]\n",
    "            if row[4] >= 0.2:\n",
    "                x1, y1, x2, y2 = int(row[0]*x_shape), int(row[1]*y_shape), int(row[2]*x_shape), int(row[3]*y_shape)\n",
    "                bgr = (0, 255, 0)\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), bgr, 2)\n",
    "                cv2.putText(frame, self.class_to_label(labels[i]), (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.9, bgr, 2)\n",
    "\n",
    "        return frame, n\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\"\n",
    "        This function is called when class is executed, it runs the loop to read the video frame by frame,\n",
    "        and write the output into a new file.\n",
    "        :return: void\n",
    "        \"\"\"\n",
    "        print(self.device)\n",
    "        filenames = glob.glob(\"video10/*.png\")\n",
    "        filenames.sort()\n",
    "        images = [cv2.imread(img) for img in filenames]\n",
    "       \n",
    "        for i in range(len(images)):\n",
    "            frame = images[i]\n",
    "            results = self.score_frame(frame, i)\n",
    "            frame, n = self.plot_boxes(results, frame)\n",
    "            cv2.imshow('object_detect', frame) # view the annotated images\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'): # close gracefully\n",
    "                player.release()\n",
    "                cv2.destroyWindow('object_detect')\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "908295a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\91947/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2021-11-23 torch 1.10.0 CUDA:0 (NVIDIA GeForce MX450, 2048MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "a = ObjectDetection(\"test1.avi\", 720, 1024, 1)\n",
    "a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ec1d84a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          car\n",
      "frame id     \n",
      "0         NaN\n",
      "1         NaN\n",
      "2         NaN\n",
      "3         NaN\n",
      "4         NaN\n",
      "...       ...\n",
      "103       NaN\n",
      "104       NaN\n",
      "105       NaN\n",
      "106       NaN\n",
      "107       NaN\n",
      "\n",
      "[108 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "file_excel = glob.glob(\"video4/*.xlsx\")\n",
    "file_excel.sort()\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "i = 0\n",
    "\n",
    "for file in file_excel:\n",
    "    df = pd.read_excel(file)\n",
    "    df = df[(df.confidence > 0.6)]\n",
    "    df1 = df.groupby(['name']).count()\n",
    "    df1 = df1.drop( columns = ['xmin','ymin','xmax','ymax', 'confidence'])\n",
    "    df1 = df1[(\"class\")]\n",
    "    arr = df1.to_dict()\n",
    "    arr ['frame id'] = i\n",
    "    x = pd.DataFrame([arr])\n",
    "    x = x.set_index('frame id')\n",
    "#     print(arr)\n",
    "    \n",
    "    if i == 0:\n",
    "        df2 = x\n",
    "    else:\n",
    "        df2 = pd.concat([df2,x], axis = 0)\n",
    "    i = i+1\n",
    "#     print(i)\n",
    "#     if i ==3:        \n",
    "#     break\n",
    "\n",
    "\n",
    "# print(df1)\n",
    "print(df2)\n",
    "    \n",
    "df2.to_excel('final_video4.xlsx')  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
